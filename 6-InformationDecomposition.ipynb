{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc7a27a",
   "metadata": {},
   "source": [
    "*This jupyter notebook is part of Arizona State University's course CAS 503 (Fundamentals of Complex Systems Science: Collectives) and was written by Bryan Daniels.  It was last updated February 13, 2022.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e1e6e",
   "metadata": {},
   "source": [
    "*The neural data we use in this module comes from the following publications (see [http://www.cns.nyu.edu/kianilab/Datasets.html](http://www.cns.nyu.edu/kianilab/Datasets.html)):*\n",
    "\n",
    "* *Kiani R, Cueva CJ, Reppas JB, Newsome WT. (2014). Dynamics of neural population responses in prefrontal cortex indicate changes of mind on single trials. Current Biology. 24(13): 1542-1547. https://doi.org/10.1016/j.cub.2014.05.049*\n",
    "* *Kiani R, Cueva CJ, Reppas JB, Peixoto D, Ryu SI, Newsome WT. (2015). Natural grouping of neural responses reveals spatially segregated clusters in prearcuate cortex. Neuron. 85(6): 1359-1373. https://dx.doi.org/10.1016/j.neuron.2015.02.014*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b24df",
   "metadata": {},
   "source": [
    "# Using Information Decomposition to Measure Neural Synergy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50893b",
   "metadata": {},
   "source": [
    "We saw in lecture how information theory can be used to define synergy quantitatively, in terms of the predictive power one gets from measuring groups of components simultaneously that is not available by measuring the components in isolation.\n",
    "\n",
    "We also saw an example of neural activity measured in a macaque's brain carrying out a decision.  In this exercise, we will look at this real neural data, searching for information in individual neurons and pairs of neurons that best allow us to read the monkey's mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0a17c",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use matplotlib and seaborn, two popular python packages, to make plots.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.rcParams.update({'font.size': 18}) # increases font size on plots\n",
    "# The \"neural\" package contains code I wrote for working with this neural dataset \n",
    "# and for calculating the information decomposition.\n",
    "from neural.neuralData import loadBinnedSpikingData,loadBehaviorData\n",
    "import neural.informationDecomposition as info\n",
    "from pathlib import Path # to handle file paths across all operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6afce",
   "metadata": {},
   "source": [
    "First we'll load the neural and behavioral data.\n",
    "\n",
    "If you're interested in the experimental details: All times will be measured relative to the \"go cue\", when the monkey is signaled to indicate its choice.  We will focus here on 400 ms past the go cue, just after the monkey has indicated its choice. (The monkey's reaction time is around 250 ms.)  We will count neural action potentials (\"spikes\") that occur within a 100 ms time window centered on 400 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFilename = Path('data/KianiEtAl2014/T33.mat')\n",
    "\n",
    "alignName = 'go_cue'  \n",
    "time = 400 # ms post-go cue\n",
    "timeWindow = 100 # ms\n",
    "\n",
    "binnedNeuralDataRaw = loadBinnedSpikingData(dataFilename,\n",
    "                                            alignName=alignName,\n",
    "                                            timeWindow=timeWindow,\n",
    "                                            relativeMidTimes=[time,])\n",
    "# (remove time index from dataframe since we're just looking at a single timepoint)\n",
    "binnedNeuralData = binnedNeuralDataRaw.xs(time,level='time (ms)') \n",
    "\n",
    "# load data on which choice the monkey made in each trial\n",
    "choiceData = loadBehaviorData(dataFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea16d6",
   "metadata": {},
   "source": [
    "Let's look at the data we have.  Note that there are 1778 trials, and for each trial we have the choice that the monkey made (direction 1 or 2) along with the measured number of action potentials made by each of 169 neural units (within the time window we specified above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "choiceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccac007",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnedNeuralData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f596c",
   "metadata": {},
   "source": [
    "Now let's use the `histplot` function from the seaborn package to plot a histogram of the activity of neuron #78 across the 1778 trials.  (`binnedNeuralData.loc[neuronIndex]` is syntax for the pandas package that produces the row of `binnedNeuralData` at index `neuronIndex`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronIndex = 78\n",
    "sns.histplot(binnedNeuralData.loc[neuronIndex],\n",
    "             discrete=True)\n",
    "plt.xlabel(\"Number of action potentials\")\n",
    "plt.title(\"Neural unit {}\".format(neuronIndex));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756acbe",
   "metadata": {},
   "source": [
    "We see that, during this time of the trial, neuron 78 often has no activity, but sometimes it fires a number of action potentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc500dd",
   "metadata": {},
   "source": [
    "## Measuring mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e199a0",
   "metadata": {},
   "source": [
    "Now let's split this into two histograms, one for trials in which the monkey's choice was direction 1 and one for direction 2.  (There's a nice way in pandas to get just the data for trials in which the choice was 1: `binnedNeuralData.loc[neuronIndex,choiceData==1]`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96769391",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronIndex = 78\n",
    "sns.histplot([binnedNeuralData.loc[neuronIndex,choiceData==2].array,\n",
    "              binnedNeuralData.loc[neuronIndex,choiceData==1].array],\n",
    "              discrete=True)\n",
    "plt.xlabel(\"Number of action potentials\")\n",
    "plt.title(\"Neural unit {}\".format(neuronIndex))\n",
    "plt.legend(['Choice 1','Choice 2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138a0a6",
   "metadata": {},
   "source": [
    "Aha!  Neuron 78 appears to be a good indicator of the decision.\n",
    "\n",
    "**❓Without doing an explicit calculation, about how many bits of information does neuron 78 carry about the decision?**  *Hint: How much uncertainty do you have about the decision before I tell you how many action potentials neuron 78 fired?  About how much uncertainty do you have after I tell you?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db87d6",
   "metadata": {},
   "source": [
    "**✳️ Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b5529",
   "metadata": {},
   "source": [
    "Now let's use python to get a more precise estimate of the mutual information between neuron 78 and the decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb7db9",
   "metadata": {},
   "source": [
    "The `discreteMutualInfo` function takes lists of discrete data sampled from two processes and returns an estimate of the mutual information between the two (in units of bits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a22a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.discreteMutualInfo( binnedNeuralData.loc[78], choiceData )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ab018",
   "metadata": {},
   "source": [
    "So the activity of neuron 78 carries about 0.85 bits of information about the decision during this time window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000048c",
   "metadata": {},
   "source": [
    "❓**Use the `discreteMutualInfo` function to find a neural unit that has very little mutual information with the decision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114f1bb",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ ** Answer: **   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0853f3c",
   "metadata": {},
   "source": [
    "❓**What do you expect the two histograms of neural activity to look like when the mutual information is small?  Explain your answer, and then check it by plotting the analogous histograms to the ones above for the neuron you found.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798204d1",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd734fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ ** Answer: **   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f6345",
   "metadata": {},
   "source": [
    "## Measuring neural synergy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666c674",
   "metadata": {},
   "source": [
    "Now we measure the amount of information that pairs of neurons carry collectively about the decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e9a87",
   "metadata": {},
   "source": [
    "As an example, let's look at the pair of neural units with index 84 and 153.  \n",
    "❓**First, use `discreteMutualInfo` as above to compute the information that neuron 84 and neuron 153 each carry individually about the decision.  Compare this to what we got with neuron 78 above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac13915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29591a2e",
   "metadata": {},
   "source": [
    "Next, we'll ask how much information we can get about the decision if we measure *both* 84 and 153.  This is called the joint mutual information.  The function `discreteJointInfo` will estimate this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce535a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronIndexA,neuronIndexB = 84,153\n",
    "info.discreteJointInfo(choiceData,\n",
    "                       binnedNeuralData.loc[neuronIndexA],\n",
    "                       binnedNeuralData.loc[neuronIndexB])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3e2ab",
   "metadata": {},
   "source": [
    "So there is some extra information that we gain by measuring both neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa906b8",
   "metadata": {},
   "source": [
    "Recall that in the information decomposition we saw in lecture, the joint mutual information can be written as a sum of the unique information provided by each neuron, the redundant information provided by both, and the synergistic information that you can only get by measuring both at the same time.  The following code will calculate this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9848371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the datasets to use\n",
    "neuronIndexA,neuronIndexB = 84,153\n",
    "neuralDataA = binnedNeuralData.loc[neuronIndexA]\n",
    "neuralDataB = binnedNeuralData.loc[neuronIndexB]\n",
    "\n",
    "# compute the mutual information decomposition values\n",
    "uniqueA,uniqueB = info.unique(choiceData,neuralDataA,neuralDataB)\n",
    "redundant =       info.redundancy(choiceData,neuralDataA,neuralDataB)\n",
    "syn =             info.synergy(choiceData,neuralDataA,neuralDataB)\n",
    "joint =           info.discreteJointInfo(choiceData,neuralDataA,neuralDataB)\n",
    "\n",
    "# print out the results in a fancy table\n",
    "print(\"Unique neuron {:<3}: {:<1.3f} bits\".format( neuronIndexA, uniqueA ))\n",
    "print(\"Unique neuron {:<3}: {:<1.3f} bits\".format( neuronIndexB, uniqueB ))\n",
    "print(\"Redundancy:        {:<1.3f} bits\".format(redundant))\n",
    "print(\"Synergy:           {:<1.3f} bits\".format(syn))\n",
    "print(\"                  ------------\")\n",
    "print(\"Total (joint):     {:<1.3f} bits\".format(joint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e1b81",
   "metadata": {},
   "source": [
    "We can plot histograms similar to the previous section to get a better understanding for how this works.  The following code plots a separate 2D histogram for Choice 1 and Choice 2, showing the distribution of activity of the two neurons in each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronIndexA,neuronIndexB = 84,153 \n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "for choice in [1,2]:\n",
    "    plt.subplot(1,2,choice)\n",
    "    sns.histplot(binnedNeuralData.loc[:,choiceData==choice].T,\n",
    "                 x=neuronIndexA,\n",
    "                 y=neuronIndexB,\n",
    "                 discrete=True,\n",
    "                 color='C{}'.format(2-choice),\n",
    "                 cbar=True,\n",
    "                 cbar_kws={'label': 'Number of trials'})\n",
    "    plt.axis(xmin=-0.5,xmax=12.5,ymin=-0.5,ymax=12.5)\n",
    "    plt.title(\"Choice {}\".format(choice))\n",
    "    plt.xlabel(\"Number of action potentials \\n for neural unit {}\".format(neuronIndexA))\n",
    "    plt.ylabel(\"Number of action potentials \\n for neural unit {}\".format(neuronIndexB))\n",
    "plt.subplots_adjust(wspace=0.4) # change horizontal spacing of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3fdb8",
   "metadata": {},
   "source": [
    "We can also plot the corresponding histograms for the individual neurons 84 and 153 (which, by the way, correspond to summing the above 2D histograms in the vertical and horizontal directions, respectively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "for i,neuronIndex in enumerate([84,153]):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    sns.histplot([binnedNeuralData.loc[neuronIndex,choiceData==2].array,\n",
    "                  binnedNeuralData.loc[neuronIndex,choiceData==1].array],\n",
    "                  discrete=True)\n",
    "    plt.xlabel(\"Number of action potentials\")\n",
    "    plt.title(\"Neural unit {}\".format(neuronIndex))\n",
    "    plt.legend(['Choice 1','Choice 2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f426b",
   "metadata": {},
   "source": [
    "Let's try to see intuitively where redundant and synergistic information comes from in these neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5c5de",
   "metadata": {},
   "source": [
    "First, **redundant** information corresponds to being able to predict the output choice equally well by measuring the activity of either neuron individually.\n",
    "\n",
    "❓**Where in the plots above do we see evidence of this redundant information?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9d77a",
   "metadata": {},
   "source": [
    "✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705e71b",
   "metadata": {},
   "source": [
    "Second, **synergistic** information corresponds to being able to predict the output choice better after accounting for any unique or redundant information provided by measuring neurons individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b4f4c",
   "metadata": {},
   "source": [
    "Understanding how synergy arises in this case is somewhat subtle.  We can gain some intuition of redundancy and synergy by instead constructing theoretical examples of perfect correlation and \"pure\" synergy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935038a",
   "metadata": {},
   "source": [
    "## Perfect correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047c068",
   "metadata": {},
   "source": [
    "If two neurons are very correlated, we might expect them to carry redundant information.  \n",
    "❓**What do you predict the unique, redundant, synergistic, and joint information will be for two neurons that are perfectly correlated?  Check your answer by using the above information decomposition code to compute an example.** *Hint: Perfectly correlated neurons would always have exactly the same firing rate (or be rescaled versions of one another).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36615b8b",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146e5ee",
   "metadata": {},
   "source": [
    "## Pure synergy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c26eb5",
   "metadata": {},
   "source": [
    "To understand where informational synergy comes from, sometimes it's useful to think about a hypothetical case with *only* synergy.  The simplest such example is the \"exclusive OR\" function, which takes two binary numbers (each 0 or 1) and returns 1 only if the two numbers are different, returning 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c507ed",
   "metadata": {},
   "source": [
    "The following code creates lists of random 0s and 1s and then computes \"exclusive OR\" of the two: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75474363",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = 1000\n",
    "X1data = np.random.randint(2,size=numSamples)\n",
    "X2data = np.random.randint(2,size=numSamples)\n",
    "\n",
    "XORdata = np.logical_xor(X1data,X2data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5407b1b",
   "metadata": {},
   "source": [
    "Here's what the data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose([X1data,X2data,XORdata]),columns=['X1data','X2data','XORdata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950e53a",
   "metadata": {},
   "source": [
    "❓**Use the above information decomposition code to verify that XOR produces \"pure synergy\".** *Hint: Because the code estimates the values from our finite dataset, you may get values that are only close to pure synergy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e7484",
   "metadata": {},
   "source": [
    "❓***Why* is this case purely synergistic?** *Hint: Think about how much you know about the output if you are able to measure only one of X1 or X2, and compare it to the case in which you can measure both X1 and X2. If you are like me and it helps to think in pictures, you might try sketching histograms like we had above, either using code or just on a piece of paper.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca600558",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ffbc6",
   "metadata": {},
   "source": [
    "## Bonus: Wisdom of the crowd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ecb9b",
   "metadata": {},
   "source": [
    "Note that the pair of synergistic neurons contains more information in a similar way to the \"wisdom of the crowd\": When noise happens to disrupt the information of one neuron, the other neuron can compensate.  We can make this analogy with the cow-weight-guessing game more explicit by looking at whether the *average* (or, equivalently, the *sum*) over multiple neurons has more mutual information with the decision.  \n",
    "\n",
    "**Bonus question (for nothing but bragging rights):**\n",
    "\n",
    "⚛️ **Find a set of neurons whose sum predicts the decision better than any of the individual or pairs of neurons we looked at so far.  How large can you make the mutual information?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✴️ **Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
