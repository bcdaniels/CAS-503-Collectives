{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wooden-omega",
   "metadata": {},
   "source": [
    "*This jupyter notebook is part of Arizona State University's course CAS 503 (Fundamentals of Complex Systems Science: Collectives) and was written by Bryan Daniels.  It was last updated September 10, 2021.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2e609",
   "metadata": {},
   "source": [
    "*The model used in this notebook appears in the following publication:*\n",
    "* *Daniels, Bryan C., Jessica C. Flack, and David C. Krakauer. “Dual Coding Theory Explains Biphasic Collective Computation in Neural Decision-Making.” Frontiers in Neuroscience 11, 1–16 (2017). https://doi.org/10.3389/fnins.2017.00313*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922917e",
   "metadata": {},
   "source": [
    "# The Dynamics of Neural Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20baacdd",
   "metadata": {},
   "source": [
    "We have now made it far enough in the course that we have the conceptual apparatus to begin with a specific model of collective behavior, ascertain its dynamical properties, and connect these to the collective's function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191adb9c",
   "metadata": {},
   "source": [
    "In this notebook, we explore the dynamics of a simple model of neural decision-making that we saw in lecture:\n",
    "\n",
    "$$ \\frac{dx_i}{dt} = I - x_i + \\sum_j W_{i,j} \\tanh{x_j} + \\xi . $$\n",
    "Here, $x_i$ is the state of neuron $i$ and $\\frac{dx_i}{dt}$ is its rate of change; $I$ represents sensory input into the neuron; the $-x_i$ term has the effect that the neuron $i$ returns to its inactive state 0 in the absence of other inputs; $W_{i,j}$ is the strength of the synaptic connection providing input into neuron $i$ from neuron $j$; $\\tanh{x_j}$ represents the firing rate of neuron $j$ (which is a function of its own state $x_j$);  and $\\xi$ represents random noise in both synaptic currents and the input signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6324713",
   "metadata": {},
   "source": [
    "## 1) Simulations and attractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2c3c6",
   "metadata": {},
   "source": [
    "We'll use many of our usual packages, along with the `simpleNeuralModel` package that I wrote for simulating the above dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18}) # increases font size on plots\n",
    "import pandas as pd\n",
    "from neural.simpleNeuralModel import simpleNeuralDynamics,allToAllNetworkAdjacency,findFixedPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff9cc3",
   "metadata": {},
   "source": [
    "Key to the collective dynamics of this model is the network structure that is represented by the matrix $W_{i,j}$.  For simplicity, we will just assume an all-to-all network—that is, each neuron receives input equally from all other neurons.  (We'll come back to this in the bonus question.)\n",
    "\n",
    "Let's simulate 100 neurons in two different all-to-all networks, one with stronger connections and one with weaker connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e652eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up two networks on which dynamics will run\n",
    "N = 100\n",
    "strongInteractionNetworkW = 0.1*allToAllNetworkAdjacency(N)\n",
    "weakInteractionNetworkW = 0.015*allToAllNetworkAdjacency(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e2d76",
   "metadata": {},
   "source": [
    "The `simpleNeuralDynamics` function takes a connection matrix $W$ and simulates one run of the dynamics, by default running up to time 10 and setting input $I=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed096dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "simData = simpleNeuralDynamics(strongInteractionNetworkW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a71125",
   "metadata": {},
   "outputs": [],
   "source": [
    "simData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a169b",
   "metadata": {},
   "source": [
    "To visualize this, we can plot the trajectories of the states of individual neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "simData['Neuron 43'].plot()\n",
    "simData['Neuron 79'].plot()\n",
    "simData['Neuron 84'].plot()\n",
    "plt.ylabel('Neural state $x$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90cef9c",
   "metadata": {},
   "source": [
    "Now rerun the simulation 5 or 10 times and replot the dynamics.\n",
    "\n",
    "❓**What appear to be the possible behaviors of the system?  Does it seem to settle into distinct attractor states?  If so, how many?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df3b5a",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b56323",
   "metadata": {},
   "source": [
    "It is sometimes possible to find a system's fixed points without directly simulating it.  Recall from the module on attractors that by asking when the system dynamics are stationary (solving $\\frac{dx}{dt} = 0$), we find the system's fixed points.\n",
    "\n",
    "In this case, if we neglect the noise term $\\xi$ (see the equation at the start of the notebook), we can ask the computer to numerically solve for the neural fixed point states $x^*$ for which $\\frac{dx^*}{dt} = 0$.  I wrote a simple function `findFixedPoints` to do this for us, given the connection matrix $W$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461114d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedPoints = findFixedPoints(strongInteractionNetworkW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b7def",
   "metadata": {},
   "source": [
    "The function finds three fixed points:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6edae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd796cb",
   "metadata": {},
   "source": [
    "Note that all neurons have the same value in each of the three fixed point states.  This is perhaps unsurprising because all neurons are equivalent in our current setup.\n",
    "\n",
    "❓**Add horizontal lines to the plot above corresponding to these (no-noise) fixed points.**  *Hint: You can use the function `plt.hlines`.  For example, `plt.hlines(fixedPoints['Neuron 43'],xmin=0,xmax=10,linestyle='--')`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c51268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b89a56",
   "metadata": {},
   "source": [
    "❓**Based on the model dynamics you observed above, which of the fixed points are stable attractors and which are unstable?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93255cba",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab21ec5",
   "metadata": {},
   "source": [
    "❓**How does this attractor structure allow the system of neurons to make a binary decision at a collective level?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa6b0e",
   "metadata": {},
   "source": [
    "✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64bb31",
   "metadata": {},
   "source": [
    "## 2) Decision-making functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c794d",
   "metadata": {},
   "source": [
    "Now let's look at how well our simulated neural system works in making the *correct* decision when given a weak sensory input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b333ef8",
   "metadata": {},
   "source": [
    "First, we'll run the simulation with a small input $I = 0.075$ applied to each neuron, then with the opposite input $I = -0.075$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputConst = 0.075\n",
    "W = strongInteractionNetworkW\n",
    "\n",
    "simDataPositiveInput = simpleNeuralDynamics(W, inputConst = inputConst)\n",
    "simDataNegativeInput = simpleNeuralDynamics(W, inputConst = -inputConst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bea3f",
   "metadata": {},
   "source": [
    "Now plot the dynamics of one of the neurons in each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b57481",
   "metadata": {},
   "outputs": [],
   "source": [
    "simDataPositiveInput['Neuron 43'].plot(color='black')\n",
    "simDataNegativeInput['Neuron 43'].plot(color='red')\n",
    "\n",
    "plt.ylabel('State $x$ of Neuron 43')\n",
    "plt.legend(['Positive input','Negative input'],loc=(1.05,0.4))\n",
    "plt.hlines(0,xmin=0,xmax=10,color='gray') # add a horizontal line at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f062c0",
   "metadata": {},
   "source": [
    "Run this a few times to get a feeling for the typical behavior.\n",
    "\n",
    "❓**What final states would correspond to \"correct\" behavior here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e5df2",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672d1ac",
   "metadata": {},
   "source": [
    "Let's do multiple runs to get a better sense of the range of behaviors.  Here I define a function that just runs the simulation 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce76ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleNeuralDynamics_multiple(weightMatrix,numRuns=10,**kwargs):\n",
    "    \"\"\"\n",
    "    Run the simpleNeuralDynamics simulation numRuns times and return a list of data from each run.\n",
    "    \"\"\"\n",
    "    simDataList = []\n",
    "    for i in range(numRuns):\n",
    "        simData = simpleNeuralDynamics(weightMatrix,**kwargs)\n",
    "        simDataList.append(simData)\n",
    "    return simDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e579df",
   "metadata": {},
   "source": [
    "Running this now takes a bit longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a023d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simDataListPositive = simpleNeuralDynamics_multiple(W, inputConst = inputConst)\n",
    "simDataListNegative = simpleNeuralDynamics_multiple(W, inputConst = -inputConst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da848c",
   "metadata": {},
   "source": [
    "And we get a nice plot similar to the ones we saw in lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e62c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for simDataPositive in simDataListPositive:\n",
    "    simDataPositive['Neuron 43'].plot(color='black')\n",
    "for simDataNegative in simDataListNegative:\n",
    "    simDataNegative['Neuron 43'].plot(color='red')\n",
    "    \n",
    "plt.ylabel('State $x$ of Neuron 43')\n",
    "plt.hlines(0,xmin=0,xmax=10,color='gray'); # add a horizontal line at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ef0ae",
   "metadata": {},
   "source": [
    "❓**Describe how well the system is performing.  About how often do the neurons produce the correct decision?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8501e82",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238fc11",
   "metadata": {},
   "source": [
    "Now let's try to improve the accuracy by tweaking the interactions between neurons.  Specifically, we'll try using *weaker* interactions, using the `weakInteractionNetworkW` we defined at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56a1e0",
   "metadata": {},
   "source": [
    "❓**Remake the previous plot using the same positive and negative inputs, but with neurons interacting according to `weakInteractionNetworkW`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a6197",
   "metadata": {},
   "source": [
    "Hmm, this doesn't look much better!  But recall that this plot shows only the state of a single neuron.  What if we look at the aggregate, collective level?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738aebc",
   "metadata": {},
   "source": [
    "❓**Instead of the state of a single neuron, modify the above plot to show the *average state over all neurons* for each simulation run.** *Hint: To get the right average over neurons for the pandas DataFrame `simDataPositive`, use `simDataPositive.mean(axis=1)`.  Remember to correctly label your axes!  The correct plot should show the average state over all neurons as a function of time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9ebdb",
   "metadata": {},
   "source": [
    "❓**How well does the *collective* neural system perform with weak interactions?  Is the system successfully making use of the \"noise reduction\" strategy from Module 3?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d942be4",
   "metadata": {},
   "source": [
    "✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f18dde",
   "metadata": {},
   "source": [
    "❓**In words, how do the above results correspond to a speed-accuracy tradeoff?** *Hint: Compare the speed with which the system approaches the attractor decision states in the case of strong and weak interactions.  Then consider the decision accuracy in the two cases.  Do you have an intuition for why the speed of the decision affects its accuracy?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0753b",
   "metadata": {},
   "source": [
    "✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e6c17",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155c7c8",
   "metadata": {},
   "source": [
    "**Bonus questions (for nothing but bragging rights):**\n",
    "\n",
    "1)  We found above that the strength and number of interactions is critical to the speed-accuracy tradeoff, because more and stronger interactions lead to signals being quickly amplified by the dynamics. ⚛️ **Based on the previous module, what single coarse-grained number would you expect to be a good measure of this amplification in an arbitrary network (that is, a measure of how quickly perturbations spread through the system)?**\n",
    "\n",
    "2)  The all-to-all connection case is in fact simple enough that it is possible to write down a single one-dimensional equation that produces the three zero-noise fixed points. ⚛️ **Find this equation and make a plot that shows the location of the three fixed points. Check that it matches with what we found numerically above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa4ce2",
   "metadata": {},
   "source": [
    "✴️ **Answers:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
